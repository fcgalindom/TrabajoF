{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a sentiment analysis classifier based on supervised machine learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, precision_score, recall_score, f1_score ,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entro\n"
     ]
    }
   ],
   "source": [
    "print(\"entro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('spanish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    tt = TweetTokenizer()\n",
    "    return tt.tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading labeled tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset loaded from: https://docs.google.com/spreadsheets/d/11_E2ngsEOyTQwbwVVRHY5urzFF95BQCV/edit#gid=1788161364\n",
    "tweets_df = pd.read_csv('./data/tweets_labeled.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(648, 3)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@IvanDuque Sus socios de las AGC tienen este platanal vuelto mierda, pero no haces nada, usted inservible, ha logrado la peor inflaci칩n en Colombia y solo p칰blica maricadas sin sentido, se rob칩 las elecciones para entregar el pa칤s, valiente idiota tenemos de presidente.</td>\n",
       "      <td>negative</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@AlvaroUribeVel Ellos tambi칠n celebran por que Maduro PetroGustavo Ivan Cepeda Timo Teodora Bobolivar entre muchos m치s sufren  de insomnio.\\r\\nUribe Velez Alvarito no los deja dormir\\r\\nEl enemigo para las elecciones no es Fico.... Sino el Excelent칤simo y m치s Grande Presidente que ha tenido Colombia</td>\n",
       "      <td>negative</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@PDleh @cokycafe @PGN_COL En Colombia existen miles de leyes para controlar los funcionarios p칰blicos pero a la hora de aplicarlas \"se les olvida que existen\". 쯈ue m치s pruebas quieren? 쯇orque avalan unas elecciones, las del 13 de marzo, donde pado de todo lo que no deb칤a de pasar? Escuchamos  respuestas</td>\n",
       "      <td>negative</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Petro ahora es el Capit치n Am칠rica o mejor dicho el Capit치n Colombia de ganar las elecciones. No soltara el escudo ni para dormir 游땍 https://t.co/k56Dv7id1J</td>\n",
       "      <td>negative</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#OtraPregunta \\r\\n\"Petro promete reanudar relaciones diplom치ticas con Maduro si gana elecciones en Colombia\"...\\r\\nEsto no pinta nada bien... y si adem치s gana Lula en Brasil...\\r\\n쮼sto como que va para largo? https://t.co/wpQsl5KoRe</td>\n",
       "      <td>negative</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                            full_text  \\\n",
       "0                                      @IvanDuque Sus socios de las AGC tienen este platanal vuelto mierda, pero no haces nada, usted inservible, ha logrado la peor inflaci칩n en Colombia y solo p칰blica maricadas sin sentido, se rob칩 las elecciones para entregar el pa칤s, valiente idiota tenemos de presidente.   \n",
       "1        @AlvaroUribeVel Ellos tambi칠n celebran por que Maduro PetroGustavo Ivan Cepeda Timo Teodora Bobolivar entre muchos m치s sufren  de insomnio.\\r\\nUribe Velez Alvarito no los deja dormir\\r\\nEl enemigo para las elecciones no es Fico.... Sino el Excelent칤simo y m치s Grande Presidente que ha tenido Colombia   \n",
       "2  @PDleh @cokycafe @PGN_COL En Colombia existen miles de leyes para controlar los funcionarios p칰blicos pero a la hora de aplicarlas \"se les olvida que existen\". 쯈ue m치s pruebas quieren? 쯇orque avalan unas elecciones, las del 13 de marzo, donde pado de todo lo que no deb칤a de pasar? Escuchamos  respuestas   \n",
       "3                                                                                                                                                          Petro ahora es el Capit치n Am칠rica o mejor dicho el Capit치n Colombia de ganar las elecciones. No soltara el escudo ni para dormir 游땍 https://t.co/k56Dv7id1J   \n",
       "4                                                                           #OtraPregunta \\r\\n\"Petro promete reanudar relaciones diplom치ticas con Maduro si gana elecciones en Colombia\"...\\r\\nEsto no pinta nada bien... y si adem치s gana Lula en Brasil...\\r\\n쮼sto como que va para largo? https://t.co/wpQsl5KoRe   \n",
       "\n",
       "  sentiment emotion  \n",
       "0  negative   anger  \n",
       "1  negative   anger  \n",
       "2  negative   anger  \n",
       "3  negative     joy  \n",
       "4  negative    fear  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    0.404321\n",
       "NaN         0.395062\n",
       "neutral     0.166667\n",
       "positive    0.033951\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df['sentiment'].value_counts(dropna = False, normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN        0.444444\n",
       "anger      0.268519\n",
       "joy        0.135802\n",
       "fear       0.104938\n",
       "sadness    0.046296\n",
       "Name: emotion, dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df['emotion'].value_counts(dropna = False, normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leaving out unlabeled texts, this data is not useful for training or validating a supervised model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing  unlabeled tweets\n",
    "tweets_labeled_df = tweets_df.loc[tweets_df['sentiment'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392, 3)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_labeled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_unlabeled_df = tweets_df.loc[tweets_df['sentiment'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 3)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_unlabeled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_10272/778818246.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweets_labeled_df['sentiment'] = tweets_labeled_df['sentiment'].replace({'neutral': 'positive'})\n"
     ]
    }
   ],
   "source": [
    "# Scenario 1: Working with all classes\n",
    "\n",
    "# Scenario 2: Working only with positive and negative classes\n",
    "# Removing neutral class\n",
    "#tweets_labeled_df = tweets_labeled_df.loc[tweets_labeled_df['sentiment'].isin(['positive', 'negative'])]\n",
    "\n",
    "# Scenario 3: Treating neutral as positive classes\n",
    "tweets_labeled_df['sentiment'] = tweets_labeled_df['sentiment'].replace({'neutral': 'positive'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tweets_labeled_df['full_text'], tweets_labeled_df['sentiment'], test_size = 0.2, stratify = tweets_labeled_df['sentiment'], random_state = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313,)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    0.667732\n",
       "positive    0.332268\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79,)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    0.670886\n",
       "positive    0.329114\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_test).value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = CountVectorizer(tokenizer = tokenizer, stop_words = stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer = tokenizer, stop_words = stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bow = bow.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf = tfidf.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluating a model using BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_bow_predict = model.predict(X_bow)\n",
    "y_test_bow_predict = model.predict(bow.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_10272/405634926.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdisp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m,\u001b[0m   \u001b[0mdisplay_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdisp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "predictions = train_test_split.predict(X_test)\n",
    "cm = confusion_matrix(y_test, predictions, labels=clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,   display_labels=clf.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4782608695652174\n",
      "Recall: 0.4230769230769231\n",
      "F1: 0.44897959183673475\n"
     ]
    }
   ],
   "source": [
    "# Metrics calculation for binary classes\n",
    "print('Precision:', precision_score(y_test, y_test_bow_predict, pos_label = 'positive'))\n",
    "print('Recall:', recall_score(y_test, y_test_bow_predict, pos_label = 'positive'))\n",
    "print('F1:', f1_score(y_test, y_test_bow_predict, pos_label = 'positive'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: [0.73214286 0.47826087]\n",
      "Recall: [0.77358491 0.42307692]\n",
      "F1: [0.75229358 0.44897959]\n"
     ]
    }
   ],
   "source": [
    "# Metrics calculation for more than two classes\n",
    "print('Precision:', precision_score(y_test, y_test_bow_predict, average = None))\n",
    "print('Recall:', recall_score(y_test, y_test_bow_predict, average = None))\n",
    "print('F1:', f1_score(y_test, y_test_bow_predict, average = None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluating a model using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tfidf_predict = model.predict(X_tfidf)\n",
    "y_test_tfidf_predict = model.predict(bow.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'ConfusionMatrixDisplay' has no attribute 'from_predictions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_10272/938393987.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_tfidf_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'ConfusionMatrixDisplay' has no attribute 'from_predictions'"
     ]
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_train, y_train_tfidf_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'ConfusionMatrixDisplay' has no attribute 'from_predictions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_10272/336274931.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_tfidf_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'ConfusionMatrixDisplay' has no attribute 'from_predictions'"
     ]
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test, y_test_tfidf_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5333333333333333\n",
      "Recall: 0.6153846153846154\n",
      "F1: 0.5714285714285715\n"
     ]
    }
   ],
   "source": [
    "# Metrics calculation for binary classes\n",
    "print('Precision:', precision_score(y_test, y_test_tfidf_predict, pos_label = 'positive'))\n",
    "print('Recall:', recall_score(y_test, y_test_tfidf_predict, pos_label = 'positive'))\n",
    "print('F1:', f1_score(y_test, y_test_tfidf_predict, pos_label = 'positive'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: [0.79591837 0.53333333]\n",
      "Recall: [0.73584906 0.61538462]\n",
      "F1: [0.76470588 0.57142857]\n"
     ]
    }
   ],
   "source": [
    "# Metrics calculation for more than two classes\n",
    "print('Precision:', precision_score(y_test, y_test_tfidf_predict, average = None))\n",
    "print('Recall:', recall_score(y_test, y_test_tfidf_predict, average = None))\n",
    "print('F1:', f1_score(y_test, y_test_tfidf_predict, average = None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How interpret the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df = pd.concat(\n",
    "    [ pd.concat([X_test, y_test ], axis = 1).reset_index(),\n",
    "    pd.Series(y_test_bow_predict) ]\n",
    ", axis = 1).rename(columns = { 'sentiment': 'actual', 0: 'predicted' })\n",
    "\n",
    "error_df.drop('index', inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79, 3)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@GustavoBolivar Debieran inventar algo diferente est치n igual que Ch치vez y Maduro cada vez que vienen elecciones inventaba guerras con Colombia, que hab칤a intereses en matarlo y ustedes igualito inventan enfermedades, atentados etc, etc.</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>En Colombia hace falta un presidente como @nayibbukele que no le teme a nada y va de frente contra las fuerzas oscuras aliadas con pol칤ticos que lo 칰nico que buscas es inestabilidad en el pa칤s previo a elecciones.</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>En Colombia con las elecciones</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>La cuenta regresiva para las elecciones presidenciales de Colombia se encuentra en su recta final, y el candidato que cuenta de acuerdo a la encuestas con mayor intenci칩n de votos es Gustavo Petro #7May https://t.co/JVyQw3MCv7</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Con la extradici칩n de Otoniel, se llevaron un posible muy apoyado candidato a la Presidencia de Colombia en las pr칩ximas elecciones.</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                      full_text  \\\n",
       "0  @GustavoBolivar Debieran inventar algo diferente est치n igual que Ch치vez y Maduro cada vez que vienen elecciones inventaba guerras con Colombia, que hab칤a intereses en matarlo y ustedes igualito inventan enfermedades, atentados etc, etc.   \n",
       "1                         En Colombia hace falta un presidente como @nayibbukele que no le teme a nada y va de frente contra las fuerzas oscuras aliadas con pol칤ticos que lo 칰nico que buscas es inestabilidad en el pa칤s previo a elecciones.   \n",
       "3                                                                                                                                                                                                                En Colombia con las elecciones   \n",
       "6            La cuenta regresiva para las elecciones presidenciales de Colombia se encuentra en su recta final, y el candidato que cuenta de acuerdo a la encuestas con mayor intenci칩n de votos es Gustavo Petro #7May https://t.co/JVyQw3MCv7   \n",
       "7                                                                                                          Con la extradici칩n de Otoniel, se llevaron un posible muy apoyado candidato a la Presidencia de Colombia en las pr칩ximas elecciones.   \n",
       "\n",
       "     actual predicted  \n",
       "0  positive  negative  \n",
       "1  positive  negative  \n",
       "3  positive  negative  \n",
       "6  positive  negative  \n",
       "7  negative  positive  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_df.loc[error_df['actual'] != error_df['predicted']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entr\n"
     ]
    }
   ],
   "source": [
    "print(\"entr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
