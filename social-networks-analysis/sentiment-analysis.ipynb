{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a sentiment analysis classifier based on supervised machine learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, precision_score, recall_score, f1_score ,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entro\n"
     ]
    }
   ],
   "source": [
    "print(\"entro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('spanish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    tt = TweetTokenizer()\n",
    "    return tt.tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading labeled tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset loaded from: https://docs.google.com/spreadsheets/d/11_E2ngsEOyTQwbwVVRHY5urzFF95BQCV/edit#gid=1788161364\n",
    "tweets_df = pd.read_csv('./data/tweets_labeled.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(648, 3)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@IvanDuque Sus socios de las AGC tienen este platanal vuelto mierda, pero no haces nada, usted inservible, ha logrado la peor inflaci√≥n en Colombia y solo p√∫blica maricadas sin sentido, se rob√≥ las elecciones para entregar el pa√≠s, valiente idiota tenemos de presidente.</td>\n",
       "      <td>negative</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@AlvaroUribeVel Ellos tambi√©n celebran por que Maduro PetroGustavo Ivan Cepeda Timo Teodora Bobolivar entre muchos m√°s sufren  de insomnio.\\r\\nUribe Velez Alvarito no los deja dormir\\r\\nEl enemigo para las elecciones no es Fico.... Sino el Excelent√≠simo y m√°s Grande Presidente que ha tenido Colombia</td>\n",
       "      <td>negative</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@PDleh @cokycafe @PGN_COL En Colombia existen miles de leyes para controlar los funcionarios p√∫blicos pero a la hora de aplicarlas \"se les olvida que existen\". ¬øQue m√°s pruebas quieren? ¬øPorque avalan unas elecciones, las del 13 de marzo, donde pado de todo lo que no deb√≠a de pasar? Escuchamos  respuestas</td>\n",
       "      <td>negative</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Petro ahora es el Capit√°n Am√©rica o mejor dicho el Capit√°n Colombia de ganar las elecciones. No soltara el escudo ni para dormir üòÇ https://t.co/k56Dv7id1J</td>\n",
       "      <td>negative</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#OtraPregunta \\r\\n\"Petro promete reanudar relaciones diplom√°ticas con Maduro si gana elecciones en Colombia\"...\\r\\nEsto no pinta nada bien... y si adem√°s gana Lula en Brasil...\\r\\n¬øEsto como que va para largo? https://t.co/wpQsl5KoRe</td>\n",
       "      <td>negative</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                            full_text  \\\n",
       "0                                      @IvanDuque Sus socios de las AGC tienen este platanal vuelto mierda, pero no haces nada, usted inservible, ha logrado la peor inflaci√≥n en Colombia y solo p√∫blica maricadas sin sentido, se rob√≥ las elecciones para entregar el pa√≠s, valiente idiota tenemos de presidente.   \n",
       "1        @AlvaroUribeVel Ellos tambi√©n celebran por que Maduro PetroGustavo Ivan Cepeda Timo Teodora Bobolivar entre muchos m√°s sufren  de insomnio.\\r\\nUribe Velez Alvarito no los deja dormir\\r\\nEl enemigo para las elecciones no es Fico.... Sino el Excelent√≠simo y m√°s Grande Presidente que ha tenido Colombia   \n",
       "2  @PDleh @cokycafe @PGN_COL En Colombia existen miles de leyes para controlar los funcionarios p√∫blicos pero a la hora de aplicarlas \"se les olvida que existen\". ¬øQue m√°s pruebas quieren? ¬øPorque avalan unas elecciones, las del 13 de marzo, donde pado de todo lo que no deb√≠a de pasar? Escuchamos  respuestas   \n",
       "3                                                                                                                                                          Petro ahora es el Capit√°n Am√©rica o mejor dicho el Capit√°n Colombia de ganar las elecciones. No soltara el escudo ni para dormir üòÇ https://t.co/k56Dv7id1J   \n",
       "4                                                                           #OtraPregunta \\r\\n\"Petro promete reanudar relaciones diplom√°ticas con Maduro si gana elecciones en Colombia\"...\\r\\nEsto no pinta nada bien... y si adem√°s gana Lula en Brasil...\\r\\n¬øEsto como que va para largo? https://t.co/wpQsl5KoRe   \n",
       "\n",
       "  sentiment emotion  \n",
       "0  negative   anger  \n",
       "1  negative   anger  \n",
       "2  negative   anger  \n",
       "3  negative     joy  \n",
       "4  negative    fear  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    0.404321\n",
       "NaN         0.395062\n",
       "neutral     0.166667\n",
       "positive    0.033951\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df['sentiment'].value_counts(dropna = False, normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN        0.444444\n",
       "anger      0.268519\n",
       "joy        0.135802\n",
       "fear       0.104938\n",
       "sadness    0.046296\n",
       "Name: emotion, dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df['emotion'].value_counts(dropna = False, normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leaving out unlabeled texts, this data is not useful for training or validating a supervised model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing  unlabeled tweets\n",
    "tweets_labeled_df = tweets_df.loc[tweets_df['sentiment'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392, 3)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_labeled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_unlabeled_df = tweets_df.loc[tweets_df['sentiment'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 3)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_unlabeled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_10272/778818246.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweets_labeled_df['sentiment'] = tweets_labeled_df['sentiment'].replace({'neutral': 'positive'})\n"
     ]
    }
   ],
   "source": [
    "# Scenario 1: Working with all classes\n",
    "\n",
    "# Scenario 2: Working only with positive and negative classes\n",
    "# Removing neutral class\n",
    "#tweets_labeled_df = tweets_labeled_df.loc[tweets_labeled_df['sentiment'].isin(['positive', 'negative'])]\n",
    "\n",
    "# Scenario 3: Treating neutral as positive classes\n",
    "tweets_labeled_df['sentiment'] = tweets_labeled_df['sentiment'].replace({'neutral': 'positive'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tweets_labeled_df['full_text'], tweets_labeled_df['sentiment'], test_size = 0.2, stratify = tweets_labeled_df['sentiment'], random_state = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313,)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    0.667732\n",
       "positive    0.332268\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79,)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    0.670886\n",
       "positive    0.329114\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_test).value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = CountVectorizer(tokenizer = tokenizer, stop_words = stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer = tokenizer, stop_words = stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bow = bow.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf = tfidf.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluating a model using BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_bow_predict = model.predict(X_bow)\n",
    "y_test_bow_predict = model.predict(bow.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_10272/405634926.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdisp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m,\u001b[0m   \u001b[0mdisplay_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdisp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "predictions = train_test_split.predict(X_test)\n",
    "cm = confusion_matrix(y_test, predictions, labels=clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,   display_labels=clf.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4782608695652174\n",
      "Recall: 0.4230769230769231\n",
      "F1: 0.44897959183673475\n"
     ]
    }
   ],
   "source": [
    "# Metrics calculation for binary classes\n",
    "print('Precision:', precision_score(y_test, y_test_bow_predict, pos_label = 'positive'))\n",
    "print('Recall:', recall_score(y_test, y_test_bow_predict, pos_label = 'positive'))\n",
    "print('F1:', f1_score(y_test, y_test_bow_predict, pos_label = 'positive'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: [0.73214286 0.47826087]\n",
      "Recall: [0.77358491 0.42307692]\n",
      "F1: [0.75229358 0.44897959]\n"
     ]
    }
   ],
   "source": [
    "# Metrics calculation for more than two classes\n",
    "print('Precision:', precision_score(y_test, y_test_bow_predict, average = None))\n",
    "print('Recall:', recall_score(y_test, y_test_bow_predict, average = None))\n",
    "print('F1:', f1_score(y_test, y_test_bow_predict, average = None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluating a model using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tfidf_predict = model.predict(X_tfidf)\n",
    "y_test_tfidf_predict = model.predict(bow.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'ConfusionMatrixDisplay' has no attribute 'from_predictions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_10272/938393987.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_tfidf_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'ConfusionMatrixDisplay' has no attribute 'from_predictions'"
     ]
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_train, y_train_tfidf_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'ConfusionMatrixDisplay' has no attribute 'from_predictions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_10272/336274931.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_tfidf_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'ConfusionMatrixDisplay' has no attribute 'from_predictions'"
     ]
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test, y_test_tfidf_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5333333333333333\n",
      "Recall: 0.6153846153846154\n",
      "F1: 0.5714285714285715\n"
     ]
    }
   ],
   "source": [
    "# Metrics calculation for binary classes\n",
    "print('Precision:', precision_score(y_test, y_test_tfidf_predict, pos_label = 'positive'))\n",
    "print('Recall:', recall_score(y_test, y_test_tfidf_predict, pos_label = 'positive'))\n",
    "print('F1:', f1_score(y_test, y_test_tfidf_predict, pos_label = 'positive'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: [0.79591837 0.53333333]\n",
      "Recall: [0.73584906 0.61538462]\n",
      "F1: [0.76470588 0.57142857]\n"
     ]
    }
   ],
   "source": [
    "# Metrics calculation for more than two classes\n",
    "print('Precision:', precision_score(y_test, y_test_tfidf_predict, average = None))\n",
    "print('Recall:', recall_score(y_test, y_test_tfidf_predict, average = None))\n",
    "print('F1:', f1_score(y_test, y_test_tfidf_predict, average = None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How interpret the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df = pd.concat(\n",
    "    [ pd.concat([X_test, y_test ], axis = 1).reset_index(),\n",
    "    pd.Series(y_test_bow_predict) ]\n",
    ", axis = 1).rename(columns = { 'sentiment': 'actual', 0: 'predicted' })\n",
    "\n",
    "error_df.drop('index', inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79, 3)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@GustavoBolivar Debieran inventar algo diferente est√°n igual que Ch√°vez y Maduro cada vez que vienen elecciones inventaba guerras con Colombia, que hab√≠a intereses en matarlo y ustedes igualito inventan enfermedades, atentados etc, etc.</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>En Colombia hace falta un presidente como @nayibbukele que no le teme a nada y va de frente contra las fuerzas oscuras aliadas con pol√≠ticos que lo √∫nico que buscas es inestabilidad en el pa√≠s previo a elecciones.</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>En Colombia con las elecciones</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>La cuenta regresiva para las elecciones presidenciales de Colombia se encuentra en su recta final, y el candidato que cuenta de acuerdo a la encuestas con mayor intenci√≥n de votos es Gustavo Petro #7May https://t.co/JVyQw3MCv7</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Con la extradici√≥n de Otoniel, se llevaron un posible muy apoyado candidato a la Presidencia de Colombia en las pr√≥ximas elecciones.</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                      full_text  \\\n",
       "0  @GustavoBolivar Debieran inventar algo diferente est√°n igual que Ch√°vez y Maduro cada vez que vienen elecciones inventaba guerras con Colombia, que hab√≠a intereses en matarlo y ustedes igualito inventan enfermedades, atentados etc, etc.   \n",
       "1                         En Colombia hace falta un presidente como @nayibbukele que no le teme a nada y va de frente contra las fuerzas oscuras aliadas con pol√≠ticos que lo √∫nico que buscas es inestabilidad en el pa√≠s previo a elecciones.   \n",
       "3                                                                                                                                                                                                                En Colombia con las elecciones   \n",
       "6            La cuenta regresiva para las elecciones presidenciales de Colombia se encuentra en su recta final, y el candidato que cuenta de acuerdo a la encuestas con mayor intenci√≥n de votos es Gustavo Petro #7May https://t.co/JVyQw3MCv7   \n",
       "7                                                                                                          Con la extradici√≥n de Otoniel, se llevaron un posible muy apoyado candidato a la Presidencia de Colombia en las pr√≥ximas elecciones.   \n",
       "\n",
       "     actual predicted  \n",
       "0  positive  negative  \n",
       "1  positive  negative  \n",
       "3  positive  negative  \n",
       "6  positive  negative  \n",
       "7  negative  positive  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_df.loc[error_df['actual'] != error_df['predicted']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entr\n"
     ]
    }
   ],
   "source": [
    "print(\"entr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
